{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed2dc6d2-567c-44b7-a5d0-fb68c3b42468",
   "metadata": {},
   "source": [
    "# Predicting Wine Quality: A Binary Classification Approach Using Physicochemical Properties\n",
    "\n",
    "**Authors:** Aiden Hew, Karan Bains, Shuhang Li"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a2baa-006e-456b-8ecf-de69744a4eff",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This analysis investigates whether physicochemical properties (eg. alcohol content, volatile acidity, and sulphates) can reliably predict wine quality using classification. Using a dataset of 1,599 red Portuguese \"Vinho Verde\" wines, we developed models to distinguish between high-quality wines (rated 7 or higher) and lower-quality wines (rated below 7). The analysis employed logistic regression, decision trees, and random forest classifiers. Results indicate that alcohol content, volatile acidity, and sulphates are the strongest predictors of wine quality, with the random forest model achieving 87% accuracy and an AUC of 0.91. These findings suggest that automated quality assessment based on chemical properties is feasible and could support wine production quality control processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b20a8c-d6c7-4461-9f25-f43b56fbef30",
   "metadata": {},
   "source": [
    "## Methods & Results\n",
    "\n",
    "This section describes the complete analytical workflow, including data loading, preprocessing, exploratory analysis, model building, and evaluation. All code is presented with narrative explanations of the methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "650846ad-9ffc-4d35-8d16-f00ce42c6fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc, roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d5d99-ddc8-43a9-abac-f92d2f098104",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406d95ea-b423-4e5f-b4f4-2bf814f86b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for physicochemical features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000</td>\n",
       "      <td>1599.000</td>\n",
       "      <td>1599.000</td>\n",
       "      <td>1599.000</td>\n",
       "      <td>1599.000</td>\n",
       "      <td>1599.000</td>\n",
       "      <td>1599.000</td>\n",
       "      <td>1599.000</td>\n",
       "      <td>1599.000</td>\n",
       "      <td>1599.000</td>\n",
       "      <td>1599.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.320</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.271</td>\n",
       "      <td>2.539</td>\n",
       "      <td>0.087</td>\n",
       "      <td>15.875</td>\n",
       "      <td>46.468</td>\n",
       "      <td>0.997</td>\n",
       "      <td>3.311</td>\n",
       "      <td>0.658</td>\n",
       "      <td>10.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.410</td>\n",
       "      <td>0.047</td>\n",
       "      <td>10.460</td>\n",
       "      <td>32.895</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>2.740</td>\n",
       "      <td>0.330</td>\n",
       "      <td>8.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.090</td>\n",
       "      <td>1.900</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>0.996</td>\n",
       "      <td>3.210</td>\n",
       "      <td>0.550</td>\n",
       "      <td>9.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.260</td>\n",
       "      <td>2.200</td>\n",
       "      <td>0.079</td>\n",
       "      <td>14.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.620</td>\n",
       "      <td>10.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.420</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.090</td>\n",
       "      <td>21.000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>3.400</td>\n",
       "      <td>0.730</td>\n",
       "      <td>11.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900</td>\n",
       "      <td>1.580</td>\n",
       "      <td>1.000</td>\n",
       "      <td>15.500</td>\n",
       "      <td>0.611</td>\n",
       "      <td>72.000</td>\n",
       "      <td>289.000</td>\n",
       "      <td>1.004</td>\n",
       "      <td>4.010</td>\n",
       "      <td>2.000</td>\n",
       "      <td>14.900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count       1599.000          1599.000     1599.000        1599.000   \n",
       "mean           8.320             0.528        0.271           2.539   \n",
       "std            1.741             0.179        0.195           1.410   \n",
       "min            4.600             0.120        0.000           0.900   \n",
       "25%            7.100             0.390        0.090           1.900   \n",
       "50%            7.900             0.520        0.260           2.200   \n",
       "75%            9.200             0.640        0.420           2.600   \n",
       "max           15.900             1.580        1.000          15.500   \n",
       "\n",
       "       chlorides  free sulfur dioxide  total sulfur dioxide   density  \\\n",
       "count   1599.000             1599.000              1599.000  1599.000   \n",
       "mean       0.087               15.875                46.468     0.997   \n",
       "std        0.047               10.460                32.895     0.002   \n",
       "min        0.012                1.000                 6.000     0.990   \n",
       "25%        0.070                7.000                22.000     0.996   \n",
       "50%        0.079               14.000                38.000     0.997   \n",
       "75%        0.090               21.000                62.000     0.998   \n",
       "max        0.611               72.000               289.000     1.004   \n",
       "\n",
       "             pH  sulphates   alcohol  \n",
       "count  1599.000   1599.000  1599.000  \n",
       "mean      3.311      0.658    10.423  \n",
       "std       0.154      0.170     1.066  \n",
       "min       2.740      0.330     8.400  \n",
       "25%       3.210      0.550     9.500  \n",
       "50%       3.310      0.620    10.200  \n",
       "75%       3.400      0.730    11.100  \n",
       "max       4.010      2.000    14.900  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/winequality-red.csv\", sep=';')\n",
    "\n",
    "# Create binary target variable for quality>=7 and quality<7\n",
    "df['quality_binary'] = (df['quality'] >= 7)\n",
    "\n",
    "# Separate features and target\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "                   'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "                   'pH', 'sulphates', 'alcohol']\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['quality_binary']\n",
    "\n",
    "# Summary statistics of all features\n",
    "print(\"Summary statistics for physicochemical features:\")\n",
    "df[feature_columns].describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48f6f174-d6c2-47a9-bd17-bc3524162e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=2025, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e7e64a-7d34-45ec-8c4d-6e428ee477d3",
   "metadata": {},
   "source": [
    "### Model Development and Training\n",
    "\n",
    "We trained three different classification algorithms to compare their performance:\n",
    "\n",
    "1. **Logistic Regression**: A linear model that estimates the probability of class membership using a logistic function.\n",
    "\n",
    "2. **Decision Tree**: A non-linear model that recursively partitions the feature space based on feature thresholds. We limit the maximum depth and require minimum samples per leaf to prevent overfitting.\n",
    "\n",
    "3. **Random Forest**: An ensemble method that combines multiple decision trees through bootstrap aggregation (bagging). This typically provides better generalization than a single decision tree.\n",
    "\n",
    "All models use class weighting (balanced) to account for the imbalanced class distribution, giving more importance to the minority class (high-quality wines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c04ddb3-b149-4a20-8dbe-d03d00fa9397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "  Train Accuracy: 0.7928\n",
      "  Test Accuracy: 0.7594\n",
      "  Precision: 0.3455\n",
      "  Recall: 0.8837\n",
      "  F1 Score: 0.4967\n",
      "  ROC AUC: 0.8797\n",
      "\n",
      "Training Decision Tree...\n",
      "  Train Accuracy: 0.8757\n",
      "  Test Accuracy: 0.7656\n",
      "  Precision: 0.3298\n",
      "  Recall: 0.7209\n",
      "  F1 Score: 0.4526\n",
      "  ROC AUC: 0.7845\n",
      "\n",
      "Training Random Forest...\n",
      "  Train Accuracy: 0.9578\n",
      "  Test Accuracy: 0.8844\n",
      "  Precision: 0.5577\n",
      "  Recall: 0.6744\n",
      "  F1 Score: 0.6105\n",
      "  ROC AUC: 0.9212\n"
     ]
    }
   ],
   "source": [
    "# Initialize models with class balancing\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        random_state=123, \n",
    "        max_iter=1000, \n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    'Decision Tree': DecisionTreeClassifier(\n",
    "        random_state=123, \n",
    "        max_depth=10, \n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        random_state=123, \n",
    "        max_depth=15,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train models and store results\n",
    "trained_models = {}\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    y_test_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    precision = precision_score(y_test, y_test_pred)\n",
    "    recall = recall_score(y_test, y_test_pred)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train Accuracy': train_acc,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ROC AUC': roc_auc\n",
    "    })\n",
    "    \n",
    "    print(f\"  Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  ROC AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b2fbb0-8aec-4bf9-aef0-321efcd660bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross-Validation Results (Random Forest):\n",
      "  Fold accuracies: ['0.8828', '0.8906', '0.8672', '0.8828', '0.9020']\n",
      "  Mean CV Accuracy: 0.8851\n",
      "  Std CV Accuracy: 0.0114\n",
      "\n",
      "This suggests our model generalizes well with consistent performance across folds.\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-fold cross-validation on the best model\n",
    "best_model = trained_models['Random Forest']\n",
    "cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"5-Fold Cross-Validation Results (Random Forest):\")\n",
    "print(f\"  Fold accuracies: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "print(f\"  Mean CV Accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"  Std CV Accuracy: {cv_scores.std():.4f}\")\n",
    "print(f\"\\nThis suggests our model generalizes well with consistent performance across folds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wine-quality]",
   "language": "python",
   "name": "conda-env-wine-quality-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
